{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"1c472d3f56e1d3981a3fd37d3eee44d1ccdd21bd4124bc6c2c96c1c4dcfe0833"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transformer from scratch\n\nThis notebook builds a simple Transformer from scratch (Multi-Head Attention, Scaled Dot-Product Attention and Causal Masking included) in tensorflow.\n\nIt serves to demonstrate how each part of the Transformer works and how they all fit together.\n\nThe Transformer is then tested on a simple seq2seq task: translating sentences from English to French.\n\n[<img src=\"https://ar5iv.labs.arxiv.org/html/1706.03762/assets/Figures/ModalNet-21.png\" width=\"300\">](https://arxiv.org/abs/1706.03762)\n\n**Steps :**\n1. [Preparing the data](#Preparing-the-data)\n2. [Building the Transformer](#Building-the-Transformer)\n3. [Training the Transformer](#Training-the-Transformer)\n4. [Testing the Transformer](#Testing-the-Transformer)\n    \n*[Credits and stuff](#Credits-and-stuff)*","metadata":{"execution":{"iopub.execute_input":"2023-03-07T21:56:23.313623Z","iopub.status.busy":"2023-03-07T21:56:23.313156Z","iopub.status.idle":"2023-03-07T21:56:23.320534Z","shell.execute_reply":"2023-03-07T21:56:23.318865Z","shell.execute_reply.started":"2023-03-07T21:56:23.313584Z"}}},{"cell_type":"code","source":"import os\nimport random\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport string\nimport re\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:23:52.029669Z","iopub.execute_input":"2023-03-08T19:23:52.030266Z","iopub.status.idle":"2023-03-08T19:23:54.904426Z","shell.execute_reply.started":"2023-03-08T19:23:52.030218Z","shell.execute_reply":"2023-03-08T19:23:54.903327Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"print(f\"Tensor Flow Version: {tf.__version__}\")\nprint()\ngpu = len(tf.config.list_physical_devices('GPU'))>0\nprint(\"GPU is\", \"AVAILABLE\" if gpu else \"NOT AVAILABLE\")","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:23:54.911146Z","iopub.execute_input":"2023-03-08T19:23:54.911509Z","iopub.status.idle":"2023-03-08T19:23:54.998087Z","shell.execute_reply.started":"2023-03-08T19:23:54.911470Z","shell.execute_reply":"2023-03-08T19:23:54.996954Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Tensor Flow Version: 2.11.0\n\nGPU is AVAILABLE\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preparing the data","metadata":{}},{"cell_type":"markdown","source":"## Parsing the file","metadata":{}},{"cell_type":"code","source":"# parse the file\npath = \"/kaggle/input\"\npath = path if os.path.exists(path) else \".{}\".format(path)\n\ntext_file = os.path.join(path, \"fra-eng\", \"fra.txt\")\nwith open(text_file) as f:\n    lines = f.read().split(\"\\n\")[:-1]\ndata = []\nfor line in lines:\n    english, french = line.split(\"\\t\")\n    french = \"[start] \" + french + \" [end]\"\n    data.append((english, french))\n\n# display a few random samples just to get an idea of the data\nfor i in range(5):\n    print(data[random.randint(0, len(data))])","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:23:55.000050Z","iopub.execute_input":"2023-03-08T19:23:55.000940Z","iopub.status.idle":"2023-03-08T19:23:55.228446Z","shell.execute_reply.started":"2023-03-08T19:23:55.000897Z","shell.execute_reply":"2023-03-08T19:23:55.226437Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"('One more person will be joining us later.', '[start] Une personne de plus se joindra à nous plus tard. [end]')\n('Are you talking to yourself again?', '[start] Converses-tu encore avec toi-même ? [end]')\n('Tom was my role model.', '[start] Tom était mon modèle. [end]')\n('It would take at least three hours to do that.', '[start] Ça prendrait au moins trois heures de faire ça. [end]')\n('Where would you like to go next?', '[start] Où souhaiterais-tu aller ensuite ? [end]')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Shuffling the data and splitting it into train, validation, and test sets:","metadata":{}},{"cell_type":"code","source":"# shuffle the data\nrandom.shuffle(data)\n\n# split the data into train, validation, and test sets\ntrain = data[:int(len(data)*0.7)]\nvalidation = data[int(len(data)*0.7):int(len(data)*0.9)]\ntest = data[int(len(data)*0.9):]\n\n# display the data sets representations using a pie chart just to see the distribution of the data\nlabels = 'Train', 'Validation', 'Test'\nsizes = [len(train), len(validation), len(test)]\nexplode = (0.1, 0, 0)\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\nax1.axis('equal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:23:55.232169Z","iopub.execute_input":"2023-03-08T19:23:55.232476Z","iopub.status.idle":"2023-03-08T19:23:55.567568Z","shell.execute_reply.started":"2023-03-08T19:23:55.232445Z","shell.execute_reply":"2023-03-08T19:23:55.565846Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"## Vectorizing the data","metadata":{}},{"cell_type":"markdown","source":"This step takes our raw text data and converts it in a format that can be used by our model.\n\nTo keep things simple, we will first limit our vocabulary using the **max_tokens** parameter. We will also limit the length of each sample using the **sequence_length** parameter.\n\nEach sample (text input) will be standardize, tokenize by word, and then indexed by token.\n\nThis will result in a matrix of vectors (input IDs) of shape (batch_size, **sequence_length**).","metadata":{}},{"cell_type":"code","source":"max_tokens = 20000\nsequence_length = 30\n\n# convert to lowercase and strip all punctuations except \"[\" and \"]\", so we can tell apart the words \"start\" and \"end\" from the tokens \"[start]\" and \"[end]\"\nstrip_chars = string.punctuation\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")\n \ndef custom_standardization(input_string):\n    lowercase = tf.strings.lower(input_string)\n    return tf.strings.regex_replace(\n        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n \nsource_vectorization = tf.keras.layers.TextVectorization(\n    max_tokens=max_tokens,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n)\ntarget_vectorization = tf.keras.layers.TextVectorization(\n    max_tokens=max_tokens,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length + 1, # add +1 token to our target sentences since they'll be shifted right by 1 during training\n    standardize=custom_standardization,\n)\ntrain_source_texts = [text[0] for text in train]\ntrain_target_texts = [text[1] for text in train]\nsource_vectorization.adapt(train_source_texts)\ntarget_vectorization.adapt(train_target_texts)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:23:55.569576Z","iopub.execute_input":"2023-03-08T19:23:55.570045Z","iopub.status.idle":"2023-03-08T19:24:19.079470Z","shell.execute_reply.started":"2023-03-08T19:23:55.570001Z","shell.execute_reply":"2023-03-08T19:24:19.077845Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# display a random sample before and after vectorization just to test the vectorization\nrandom_sample = random.randint(0, len(train))\nprint(\"Source texts (one random sample):\", train_source_texts[random_sample])\nprint(\"Target texts (one random sample):\", train_target_texts[random_sample])\nprint(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\nprint(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n\n# display the decoding of the vectorized text (from vector back to text) just to test the vectorization\nsource_decoded_text = ''\nfor i in range(len(source_vectorization(train_source_texts[random_sample]))):\n    source_decoded_text += source_vectorization.get_vocabulary()[source_vectorization(train_source_texts[random_sample])[i]] + ' '\nprint(\"Source decoded texts (one random sample):\", source_decoded_text)\n\ntarget_decoded_text = ''\nfor i in range(len(target_vectorization(train_target_texts[random_sample]))):\n    target_decoded_text += target_vectorization.get_vocabulary()[target_vectorization(train_target_texts[random_sample])[i]] + ' '\nprint(\"Target decoded texts (one random sample):\", target_decoded_text)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:19.081085Z","iopub.execute_input":"2023-03-08T19:24:19.081862Z","iopub.status.idle":"2023-03-08T19:24:21.962102Z","shell.execute_reply.started":"2023-03-08T19:24:19.081820Z","shell.execute_reply":"2023-03-08T19:24:21.960950Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Source texts (one random sample): I'm sorry, I didn't hear you.\nTarget texts (one random sample): [start] Je suis désolé, je ne t'ai pas entendue. [end]\nSource vectors (one random sample): tf.Tensor(\n[ 25 201   2  54 221   3   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0], shape=(30,), dtype=int64)\nTarget vectors (one random sample): tf.Tensor(\n[   2    4   26  297    4    8  309    6 2212    3    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0], shape=(31,), dtype=int64)\nSource decoded texts (one random sample): im sorry i didnt hear you                         \nTarget decoded texts (one random sample): [start] je suis désolé je ne tai pas entendue [end]                      \n","output_type":"stream"}]},{"cell_type":"code","source":"# display the shape of our vectorized data\ntrain_source_vectors = source_vectorization(train_source_texts)\ntrain_target_vectors = target_vectorization(train_target_texts)\nprint(\"Source vectors (shape):\", train_source_vectors.shape)\nprint(\"Target vectors (shape):\", train_target_vectors.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:21.963804Z","iopub.execute_input":"2023-03-08T19:24:21.964195Z","iopub.status.idle":"2023-03-08T19:24:23.474873Z","shell.execute_reply.started":"2023-03-08T19:24:21.964156Z","shell.execute_reply":"2023-03-08T19:24:23.473544Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Source vectors (shape): (116990, 30)\nTarget vectors (shape): (116990, 31)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Building the Transformer","metadata":{}},{"cell_type":"markdown","source":"## Embedding and Position Encoding","metadata":{}},{"cell_type":"markdown","source":"This step takes our matrix of vectors (input IDs) of shape (batch_size, sequence_length) and embeds it while adding positional information.\n\nEach vector will be embedded in a low-dimensional floating-point vectors (the dimensionality of the embedding space is defined by the **embedding_size** parameter).\n\nEach embedding vector will then be augmented with positional information.\n\nThis will result in a matrix of shape (batch_size, sequence_length, **embedding_size**).","metadata":{}},{"cell_type":"code","source":"class PositionalEmbedding(tf.keras.layers.Layer):\n    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n        super().__init__(**kwargs)\n        self.token_embeddings = tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n        self.position_embeddings = tf.keras.layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n        self.sequence_length = sequence_length\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n\n    def call(self, inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start=0, limit=length, delta=1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        return tf.math.not_equal(inputs, 0)\n\n    def get_config(self):\n        config = super(PositionalEmbedding, self).get_config()\n        config.update({\n            \"output_dim\": self.output_dim,\n            \"sequence_length\": self.sequence_length,\n            \"input_dim\": self.input_dim,\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:23.476895Z","iopub.execute_input":"2023-03-08T19:24:23.477802Z","iopub.status.idle":"2023-03-08T19:24:23.487206Z","shell.execute_reply.started":"2023-03-08T19:24:23.477737Z","shell.execute_reply":"2023-03-08T19:24:23.486150Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# display the shape of our embedded data just to test the class\n\nembed_dim = 256\n\ntrain_source_embedded = PositionalEmbedding(\n    sequence_length=sequence_length,\n    input_dim=max_tokens,\n    output_dim=embed_dim,\n    name=\"source_embedding\",\n) (train_source_vectors)\n\ntrain_target_embedded = PositionalEmbedding(\n    sequence_length=sequence_length,\n    input_dim=max_tokens,\n    output_dim=embed_dim,\n    name=\"target_embedding\",\n) (train_source_vectors)\n\nprint(\"Source embedded vectors (shape):\", train_source_embedded.shape)\nprint(\"Target embedded vectors (shape):\", train_target_embedded.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:23.488814Z","iopub.execute_input":"2023-03-08T19:24:23.489272Z","iopub.status.idle":"2023-03-08T19:24:23.601569Z","shell.execute_reply.started":"2023-03-08T19:24:23.489230Z","shell.execute_reply":"2023-03-08T19:24:23.599668Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Source embedded vectors (shape): (116990, 30, 256)\nTarget embedded vectors (shape): (116990, 30, 256)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## The Attention mechanism","metadata":{}},{"cell_type":"markdown","source":"A simple implementation of a Transformer's attention mechanism from scratch.\n\nIn practice, we could just use **tf.keras.layers.MultiHeadAttention** instead of building it from scratch. 😒","metadata":{}},{"cell_type":"markdown","source":"### Scaled Dot-Product Attention","metadata":{}},{"cell_type":"markdown","source":"The scaled dot product attention is calculated as follows :\n\n***Attention(Q, K, V) = softmax(QK^T / √(d_k))V***\n\nWhere Q, K, V are the query, key, and value matrices and d_k is the dimensionality of the key matrix.\n\n[<img src=\"https://ar5iv.labs.arxiv.org/html/1706.03762/assets/Figures/ModalNet-19.png\" width=\"100\">](https://arxiv.org/abs/1706.03762)","metadata":{}},{"cell_type":"code","source":"def shape_list(x):\n    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n    static = x.shape.as_list()\n    dynamic = tf.shape(x)\n    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n\ndef attention_mask(nd, ns, *, dtype):\n    \"\"\"1's in the lower triangle, counting from the lower right corner.\n    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n    \"\"\"\n    i = tf.range(nd)[:,None]\n    j = tf.range(ns)\n    m = i >= j - ns + nd\n    return tf.cast(m, dtype)\n\ndef mask_attn_weights(w):\n    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n    _, _, nd, ns = shape_list(w)\n    b = attention_mask(nd, ns, dtype=w.dtype)\n    b = tf.reshape(b, [1, 1, nd, ns])\n    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n    return w\n    \ndef scaled_dot_product_attention(q, k, v, use_causal_mask=False):\n    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n    scores = tf.matmul(q, k, transpose_b=True) # Matmul of Q and K\n    scaled_scores = scores / tf.math.sqrt(d_k) # Scale\n    if use_causal_mask:\n        scaled_scores = mask_attn_weights(scaled_scores) # Mask (opt.)\n    weights = tf.nn.softmax(scaled_scores, axis=-1) # SoftMax\n    outputs = tf.matmul(weights, v) # Matmul of SoftMax and V\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:23.603092Z","iopub.execute_input":"2023-03-08T19:24:23.603502Z","iopub.status.idle":"2023-03-08T19:24:23.616082Z","shell.execute_reply.started":"2023-03-08T19:24:23.603461Z","shell.execute_reply":"2023-03-08T19:24:23.615011Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# display the shape of our attention output just to test the function\ninput = train_source_embedded\ninput = tf.expand_dims(input, axis=1)\nprint(\"Scaled dot product attention (shape):\", scaled_dot_product_attention(input, input, input, use_causal_mask=True).shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:23.617468Z","iopub.execute_input":"2023-03-08T19:24:23.618698Z","iopub.status.idle":"2023-03-08T19:24:24.101127Z","shell.execute_reply.started":"2023-03-08T19:24:23.618655Z","shell.execute_reply":"2023-03-08T19:24:24.099956Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Scaled dot product attention (shape): (116990, 1, 30, 256)\n","output_type":"stream"}]},{"cell_type":"code","source":"# display the masking of a random tensor just to test the function\nrandom_tensor = tf.random.uniform(shape=(1, 1, 5, 5), minval=0, maxval=1, dtype=tf.float32)\nprint(\"Masked attention weights:\", mask_attn_weights(random_tensor))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:24.102601Z","iopub.execute_input":"2023-03-08T19:24:24.103357Z","iopub.status.idle":"2023-03-08T19:24:24.190509Z","shell.execute_reply.started":"2023-03-08T19:24:24.103312Z","shell.execute_reply":"2023-03-08T19:24:24.189442Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Masked attention weights: tf.Tensor(\n[[[[ 1.59944177e-01 -1.00000000e+10 -1.00000000e+10 -1.00000000e+10\n    -1.00000000e+10]\n   [ 1.98841095e-02  6.20521903e-01 -1.00000000e+10 -1.00000000e+10\n    -1.00000000e+10]\n   [ 8.04124475e-01  3.30407619e-02  3.17059875e-01 -1.00000000e+10\n    -1.00000000e+10]\n   [ 1.60982728e-01  1.24920964e-01  3.91911626e-01  2.50247002e-01\n    -1.00000000e+10]\n   [ 3.89785767e-02  9.60114241e-01  1.52646184e-01  7.21741796e-01\n     9.14231658e-01]]]], shape=(1, 1, 5, 5), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Multi-Head Attention","metadata":{}},{"cell_type":"markdown","source":"The multi-head attention is calculated as follows :\n\n***MultiHead(Q, K, V) = Concat(head_1, ..., head_h)W^O***\n\nWhere head_i is the i-th attention head, W^O is the output matrix, and **h** is the number of attention heads.\n    \n[<img src=\"https://ar5iv.labs.arxiv.org/html/1706.03762/assets/Figures/ModalNet-20.png\" width=\"200\">](https://arxiv.org/abs/1706.03762)","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, h, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.h = h\n        if embed_dim % h != 0:\n            raise ValueError(\n                f\"dimension of the embedding space = {embed_dim} should be divisible by number of heads = {h}\"\n            )\n        self.q_linear = tf.keras.layers.Dense(embed_dim)\n        self.k_linear = tf.keras.layers.Dense(embed_dim)\n        self.v_linear = tf.keras.layers.Dense(embed_dim)\n        self.concat_linear = tf.keras.layers.Dense(embed_dim)\n\n    def split_heads(self, x, batch_size):\n        x = tf.reshape(x, shape=(batch_size, -1, self.h, self.embed_dim // self.h))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n    \n    def concat_heads(self, x, batch_size):\n        x = tf.transpose(x, perm=[0, 2, 1, 3])\n        return tf.reshape(x, (batch_size, -1, self.embed_dim))\n\n    def call(self, q, k, v, use_causal_mask=False):\n        batch_size = tf.shape(k)[0]\n        q = self.q_linear(q)\n        k = self.k_linear(k)\n        v = self.v_linear(v)\n        q = self.split_heads(q, batch_size)\n        k = self.split_heads(k, batch_size)\n        v = self.split_heads(v, batch_size)\n        attention = scaled_dot_product_attention(q, k, v, use_causal_mask)\n        concat = self.concat_heads(attention, batch_size)\n        concat = self.concat_linear(concat)\n        return concat\n\n    def get_config(self):\n        config = super(MultiHeadAttention, self).get_config()\n        config.update({\n            \"embed_dim\": self.embed_dim,\n            \"h\": self.h,\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:24.195209Z","iopub.execute_input":"2023-03-08T19:24:24.195494Z","iopub.status.idle":"2023-03-08T19:24:24.209205Z","shell.execute_reply.started":"2023-03-08T19:24:24.195467Z","shell.execute_reply":"2023-03-08T19:24:24.207553Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## The Encoder","metadata":{}},{"cell_type":"markdown","source":"[<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/main/images/chapter03_encoder-zoom.png\" width=\"400\">](https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)\n\n\nIn the Encoder's Multi-Head Self-Attention layer ([Global self-attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_global_self_attention_layer)), the **Source Vectors Embeddings** are being passed to all three parameters : **Q**uery, **K**ey, and **V**alue.","metadata":{}},{"cell_type":"code","source":"class TransformerEncoder(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n        self.global_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n        self.feed_forward = tf.keras.Sequential(\n            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"),\n             tf.keras.layers.Dense(embed_dim),]\n        )\n        \n    def call(self, x):\n        # Post layer normalization\n        x = self.layer_norm_1(x + self.global_self_attention(q=x, k=x, v=x))\n        x = self.layer_norm_2(x + self.feed_forward(x))\n        return x\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"embed_dim\": self.embed_dim,\n            \"dense_dim\": self.dense_dim,\n            \"num_heads\": self.num_heads,\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:24.210842Z","iopub.execute_input":"2023-03-08T19:24:24.211345Z","iopub.status.idle":"2023-03-08T19:24:24.224239Z","shell.execute_reply.started":"2023-03-08T19:24:24.211300Z","shell.execute_reply":"2023-03-08T19:24:24.223076Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## The Decoder","metadata":{}},{"cell_type":"markdown","source":"[<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/main/images/chapter03_decoder-zoom.png\" width=\"500\">](https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)\n\n\nIn the Decoder's Masked Multi-Head Self-Attention layer ([Causal self-attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_causal_self_attention_layer)), the **Target Vectors Embeddings** are being passed to all three parameters : **Q**uery, **K**ey, and **V**alue.\n\nIn the Decoder’s Encoder-Decoder Attention layer ([Cross attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_cross_attention_layer)), the **outputs of the Encoder** are being passed to the **K**ey and **V**alue parameters, with the **outputs of the Decoder's Masked Multi-Head Self-Attention layer** being passed to the **Q**uery parameter.","metadata":{}},{"cell_type":"code","source":"class TransformerDecoder(tf.keras.layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.causal_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n        self.cross_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n        self.feed_forward = tf.keras.Sequential(\n            [tf.keras.layers.Dense(dense_dim, activation=\"relu\"),\n             tf.keras.layers.Dense(embed_dim),]\n        )\n        self.layer_norm_1 = tf.keras.layers.LayerNormalization()\n        self.layer_norm_2 = tf.keras.layers.LayerNormalization()\n        self.layer_norm_3 = tf.keras.layers.LayerNormalization()\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"embed_dim\": self.embed_dim,\n            \"dense_dim\": self.dense_dim,\n            \"num_heads\": self.num_heads,\n        })\n        return config\n\n    def call(self, x, context):\n        # Post layer normalization\n        x = self.layer_norm_1(x + self.causal_self_attention(q=x, k=x, v=x, use_causal_mask=True))\n        x = self.layer_norm_2(x + self.cross_attention(q=x, k=context, v=context))\n        x = self.layer_norm_3(x + self.feed_forward(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:24.225844Z","iopub.execute_input":"2023-03-08T19:24:24.226623Z","iopub.status.idle":"2023-03-08T19:24:24.242117Z","shell.execute_reply.started":"2023-03-08T19:24:24.226540Z","shell.execute_reply":"2023-03-08T19:24:24.240731Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Putting it all together","metadata":{}},{"cell_type":"markdown","source":"[<img src=\"https://ar5iv.labs.arxiv.org/html/1706.03762/assets/Figures/ModalNet-21.png\" width=\"300\">](https://arxiv.org/abs/1706.03762)\n\nWe  turn our data into a tf.data pipeline. We want it to return a tuple (Inputs, Outputs) where Inputs is a dict with two keys, “encoder_inputs” (the source sequence) and “decoder_inputs” (the target sequence), and Outputs is a single key (the target sentence \"shifted right\").\n\nThe role of the decoder is to look at the target sequence so far and predicts the target sequence offset by one step ahead (\"shifted right\"). During inference, we generate one target token at a time and feed it back into the decoder.","metadata":{}},{"cell_type":"code","source":"batch_size = 64\n\ndef format_dataset(source, target):\n    source_vectors = source_vectorization(source)\n    target_vectors = target_vectorization(target)\n    return ({\n        \"source\": source_vectors, # encoder_inputs\n        \"target\": target_vectors[:, :-1], # decoder_inputs (truncate by 1 to keep it at the same length as decoder_outputs (which is shifted right by 1).\n    }, target_vectors[:, 1:]) # decoder_outputs\n\ndef make_dataset(texts):\n    source_texts, target_texts = zip(*texts)\n    source_texts = list(source_texts)\n    target_texts = list(target_texts)\n    dataset = tf.data.Dataset.from_tensor_slices((source_texts, target_texts))\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n    return dataset.shuffle(2048).prefetch(16).cache()\n\ntrain_ds = make_dataset(train)\nvalidation_ds = make_dataset(validation)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:24.243941Z","iopub.execute_input":"2023-03-08T19:24:24.244399Z","iopub.status.idle":"2023-03-08T19:24:26.117121Z","shell.execute_reply.started":"2023-03-08T19:24:24.244358Z","shell.execute_reply":"2023-03-08T19:24:26.116074Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#display the shape of the first batch of data in the dataset just to see what it looks like\nfor batch in train_ds.take(1):\n    print(\"Encoder Inputs:\", batch[0][\"source\"].shape)\n    print(\"Decoder Inputs:\", batch[0][\"target\"].shape)\n    print(\"Decoder Outputs:\", batch[1].shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:26.118776Z","iopub.execute_input":"2023-03-08T19:24:26.119218Z","iopub.status.idle":"2023-03-08T19:24:26.823057Z","shell.execute_reply.started":"2023-03-08T19:24:26.119129Z","shell.execute_reply":"2023-03-08T19:24:26.821972Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Encoder Inputs: (64, 30)\nDecoder Inputs: (64, 30)\nDecoder Outputs: (64, 30)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"[<img src=\"https://raw.githubusercontent.com/nlp-with-transformers/notebooks/main/images/chapter03_transformer-encoder-decoder.png\" width=\"600\">](https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)\n","metadata":{}},{"cell_type":"code","source":"embed_dim = 512 # dimension of the embedding space\ndense_dim = 2048 # dimension of the feed forward network (a rule of thumb is to use 4 times the size of the embeddings)\nnum_heads = 8\n\n# transformer body\nencoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\nx = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\nencoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\ndecoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\nx = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\nx = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n\n# transformer head\nx = tf.keras.layers.Dropout(0.5)(x)\ndecoder_outputs = tf.keras.layers.Dense(max_tokens, activation=\"softmax\")(x)\n\ntransformer = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:26.824955Z","iopub.execute_input":"2023-03-08T19:24:26.825352Z","iopub.status.idle":"2023-03-08T19:24:27.977197Z","shell.execute_reply.started":"2023-03-08T19:24:26.825312Z","shell.execute_reply":"2023-03-08T19:24:27.976138Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Training the Transformer","metadata":{}},{"cell_type":"code","source":"transformer.compile(\n    optimizer=\"rmsprop\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"])\n\nEPOCHS = 50\ncheckpoint_filepath = '/tmp/checkpoint/'\ncallbacks_list = [\n    tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.1,\n        patience=3,\n    ),\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=6,\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_filepath,\n        save_weights_only=True,\n        monitor='val_loss',\n        mode='min',\n        save_best_only=True\n    ),\n]\n    \ntransformer.fit(train_ds, \n                epochs=EPOCHS, \n                callbacks=callbacks_list,\n                validation_data=validation_ds)\n\ntransformer.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:24:27.978669Z","iopub.execute_input":"2023-03-08T19:24:27.979075Z","iopub.status.idle":"2023-03-08T20:21:09.534820Z","shell.execute_reply.started":"2023-03-08T19:24:27.979035Z","shell.execute_reply":"2023-03-08T20:21:09.533821Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/50\n1828/1828 [==============================] - 201s 105ms/step - loss: 0.9964 - accuracy: 0.8495 - val_loss: 0.6110 - val_accuracy: 0.8953 - lr: 0.0010\nEpoch 2/50\n1828/1828 [==============================] - 177s 97ms/step - loss: 0.5747 - accuracy: 0.9002 - val_loss: 0.4923 - val_accuracy: 0.9102 - lr: 0.0010\nEpoch 3/50\n1828/1828 [==============================] - 176s 96ms/step - loss: 0.4704 - accuracy: 0.9127 - val_loss: 0.4513 - val_accuracy: 0.9156 - lr: 0.0010\nEpoch 4/50\n1828/1828 [==============================] - 175s 96ms/step - loss: 0.4095 - accuracy: 0.9206 - val_loss: 0.4314 - val_accuracy: 0.9184 - lr: 0.0010\nEpoch 5/50\n1828/1828 [==============================] - 175s 96ms/step - loss: 0.3665 - accuracy: 0.9267 - val_loss: 0.4260 - val_accuracy: 0.9199 - lr: 0.0010\nEpoch 6/50\n1828/1828 [==============================] - 175s 96ms/step - loss: 0.3324 - accuracy: 0.9320 - val_loss: 0.4171 - val_accuracy: 0.9225 - lr: 0.0010\nEpoch 7/50\n1828/1828 [==============================] - 175s 96ms/step - loss: 0.3044 - accuracy: 0.9362 - val_loss: 0.4160 - val_accuracy: 0.9240 - lr: 0.0010\nEpoch 8/50\n1828/1828 [==============================] - 175s 96ms/step - loss: 0.2807 - accuracy: 0.9401 - val_loss: 0.4152 - val_accuracy: 0.9250 - lr: 0.0010\nEpoch 9/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.2609 - accuracy: 0.9435 - val_loss: 0.4218 - val_accuracy: 0.9252 - lr: 0.0010\nEpoch 10/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.2428 - accuracy: 0.9466 - val_loss: 0.4189 - val_accuracy: 0.9266 - lr: 0.0010\nEpoch 11/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.2260 - accuracy: 0.9495 - val_loss: 0.4275 - val_accuracy: 0.9267 - lr: 0.0010\nEpoch 12/50\n1828/1828 [==============================] - 175s 96ms/step - loss: 0.1552 - accuracy: 0.9620 - val_loss: 0.3678 - val_accuracy: 0.9344 - lr: 1.0000e-04\nEpoch 13/50\n1828/1828 [==============================] - 175s 96ms/step - loss: 0.1275 - accuracy: 0.9674 - val_loss: 0.3648 - val_accuracy: 0.9349 - lr: 1.0000e-04\nEpoch 14/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.1160 - accuracy: 0.9697 - val_loss: 0.3658 - val_accuracy: 0.9352 - lr: 1.0000e-04\nEpoch 15/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.1079 - accuracy: 0.9714 - val_loss: 0.3666 - val_accuracy: 0.9353 - lr: 1.0000e-04\nEpoch 16/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.1016 - accuracy: 0.9726 - val_loss: 0.3694 - val_accuracy: 0.9354 - lr: 1.0000e-04\nEpoch 17/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.0938 - accuracy: 0.9744 - val_loss: 0.3667 - val_accuracy: 0.9356 - lr: 1.0000e-05\nEpoch 18/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.0921 - accuracy: 0.9747 - val_loss: 0.3666 - val_accuracy: 0.9356 - lr: 1.0000e-05\nEpoch 19/50\n1828/1828 [==============================] - 174s 95ms/step - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.3666 - val_accuracy: 0.9356 - lr: 1.0000e-05\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f2df8556990>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Testing the Transformer","metadata":{}},{"cell_type":"markdown","source":"Let's translate a few random test sentences with our trained Transformer.","metadata":{}},{"cell_type":"code","source":"target_vocab = target_vectorization.get_vocabulary()\ntarget_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\nmax_decoded_sentence_length = 30\n\ndef decode_sequence(input_sentence):\n    tokenized_input_sentence = source_vectorization([input_sentence])\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        tokenized_target_sentence = target_vectorization(\n            [decoded_sentence])[:, :-1]\n        predictions = transformer(\n            [tokenized_input_sentence, tokenized_target_sentence])\n        sampled_token_index = np.argmax(predictions[0, i, :])\n        sampled_token = target_index_lookup[sampled_token_index]\n        decoded_sentence += \" \" + sampled_token\n        if sampled_token == \"[end]\":\n            break\n    return decoded_sentence\n\ntest_source_texts = [text[0] for text in test]\n\n# let's translate 50 random sentences\nfor _ in range(50):\n    input_sentence = random.choice(test_source_texts)\n    print(\"-\")\n    print(input_sentence)\n    print(decode_sequence(input_sentence))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T20:21:09.536573Z","iopub.execute_input":"2023-03-08T20:21:09.536971Z","iopub.status.idle":"2023-03-08T20:21:31.040562Z","shell.execute_reply.started":"2023-03-08T20:21:09.536923Z","shell.execute_reply":"2023-03-08T20:21:31.039336Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"-\nTom and Mary were both alcoholics.\n[start] tom et mary étaient tous les deux [UNK] [end]\n-\nI don't need a doctor.\n[start] je nai pas besoin dun médecin [end]\n-\nThey missed the deadline.\n[start] ils ont loupé la date limite [end]\n-\nI'll be there in five minutes.\n[start] je serai là dans cinq minutes [end]\n-\nI was surprised by what I learned.\n[start] jai été surpris par ce que jai appris [end]\n-\nYou're not allowed to eat those.\n[start] vous nêtes pas autorisée à manger ceuxlà [end]\n-\nYou have only to push this button.\n[start] tu nas que pour pousser sur ce bouton [end]\n-\nYou don't kick a man when he's down.\n[start] tu [UNK] pas un homme quand il est en panne [end]\n-\nHe has a big truck.\n[start] il a un grand camion [end]\n-\nThis job has no future.\n[start] ce boulot na pas de futur [end]\n-\nThere's no more ointment.\n[start] il ny a pas plus de [UNK] [end]\n-\nDon't read in this room.\n[start] ne lis pas dans cette pièce [end]\n-\nTell Tom I'll be back.\n[start] dis à tom que je serai de retour [end]\n-\nYou're so wrong.\n[start] vous avez tellement tort [end]\n-\nHow many sandwiches are there left?\n[start] combien de sandwiches y atil [UNK] [end]\n-\nThis dress fits me very well.\n[start] cette robe me convient très bien [end]\n-\nHe walked away with a sad look on his face.\n[start] il sen est parti avec [UNK] en face à face [end]\n-\nAnother bottle of wine, please.\n[start] une autre bouteille de vin sil vous plaît [end]\n-\nMay I sit next to you?\n[start] puisje masseoir auprès de vous [end]\n-\nI must have my watch repaired.\n[start] je dois faire réparer ma montre [end]\n-\nThe advantages outweigh the disadvantages.\n[start] les avantages [UNK] les [UNK] [end]\n-\n1989 was a difficult year.\n[start] il y a eu une année de année de lui [end]\n-\nHe has been very busy this week.\n[start] il a été très occupé cette semaine [end]\n-\nIt's later than you think.\n[start] il est plus tard que tu ne penses [end]\n-\nWhen he got to the station, the train had already left.\n[start] lorsquil est arrivé à la gare le train était déjà parti [end]\n-\nAre you vegetarian?\n[start] estu végétarienne [end]\n-\nThe child is sleeping on his stomach.\n[start] lenfant dort sur le ventre [end]\n-\nNo way!\n[start] aucun moyen [end]\n-\nMight I ask your name?\n[start] je pourrais demander votre nom [end]\n-\nGet back here.\n[start] retournez ici [end]\n-\nCommit these words to memory.\n[start] imprimez ces mots dans votre mémoire [end]\n-\nTom has done that only once.\n[start] tom a fait ça seulement une fois [end]\n-\nThey say that I'm an old woman.\n[start] ils disent que je suis une vieille femme [end]\n-\nThe sky is clear.\n[start] le ciel est clair [end]\n-\nWho is this guy?\n[start] qui est ce type [end]\n-\nHe has a Japanese car.\n[start] il a une voiture japonaise [end]\n-\nThey never gave up.\n[start] ils nont jamais abandonné [end]\n-\nYou don't look like your dad.\n[start] tu nas pas lair de ton père [end]\n-\nI left my umbrella behind in the taxi.\n[start] jai laissé mon parapluie dans le taxi [end]\n-\nHe appeared from nowhere.\n[start] il est apparu de nulle part [end]\n-\nI'm free every day but Monday.\n[start] je suis libre chaque jour mais lundi [end]\n-\nWe have an open relationship.\n[start] nous avons une relation [UNK] [end]\n-\nI'm proud of my father.\n[start] je suis fier de mon père [end]\n-\nWhat's new?\n[start] quoi de neuf de neuf ans [end]\n-\nThey were all teachers.\n[start] ils étaient tous enseignants [end]\n-\nWhat's today's date?\n[start] quelle est le jour où se [UNK] [end]\n-\nI'm not sure if he saw it.\n[start] je ne suis pas sûr quil lait vu [end]\n-\nIt won't take so long.\n[start] Ça ne prendra pas tant de temps [end]\n-\nI'm not going to tell you again.\n[start] je ne vais pas te le répéter [end]\n-\nI wrote him a letter asking him to come home soon.\n[start] je lui ai écrit une lettre chez lui bientôt à la maison [end]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Credits and stuff\n\n- https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-11\n\n- https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part03_transformer.ipynb\n\n- https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter11_part04_sequence-to-sequence-learning.ipynb\n\n- https://www.oreilly.com/library/view/natural-language-processing/9781098136789/ch03.html\n\n- https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb\n\n- https://arxiv.org/abs/1706.03762\n\n- https://www.tensorflow.org/text/tutorials/transformer\n\n- https://github.com/karpathy/minGPT/blob/master/mingpt/model.py\n\n- https://github.com/openai/gpt-2/blob/master/src/model.py\n\n","metadata":{}}]}